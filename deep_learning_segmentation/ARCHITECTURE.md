# Architecture U-Net 3D pour Segmentation d'Hologrammes

## ğŸ“‹ Vue d'ensemble

Ce document dÃ©crit l'architecture du rÃ©seau de neurones utilisÃ© pour la segmentation volumÃ©trique 3D d'hologrammes de bactÃ©ries, ainsi que les choix de design motivÃ©s par les contraintes spÃ©cifiques du problÃ¨me.

---

## ğŸ¯ ProblÃ¨me Ã  rÃ©soudre

### Contexte
- **EntrÃ©e** : Hologrammes 2D (512Ã—512 pixels) de bactÃ©ries en suspension
- **Objectif** : Segmenter les bactÃ©ries dans le volume 3D reconstruit (512Ã—512Ã—200 voxels)
- **DÃ©fi principal** : **DÃ©sÃ©quilibre extrÃªme des classes**
  - Volume total : ~52 millions de voxels
  - Objets : ~20 bactÃ©ries Ã— 20 voxels = 400 voxels positifs
  - **Ratio positif : 0.00076%** (1 voxel sur 130,000)

### DÃ©fis spÃ©cifiques
1. **Bruit de diffraction** : Le volume reconstruit contient beaucoup de bruit de diffraction dans les rÃ©gions "vides"
2. **Objets rares** : Les bactÃ©ries reprÃ©sentent une fraction infime du volume
3. **SÃ©paration d'objets proches** : Le modÃ¨le doit gÃ©rer le cas oÃ¹ la diffraction de deux bactÃ©ries proches se chevauche
4. **Faux positifs critiques** : Le modÃ¨le doit rejeter le bruit tout en dÃ©tectant avec certitude les vraies bactÃ©ries

---

## ğŸ—ï¸ Architecture U-Net 3D

### Choix architectural : U-Net

**Pourquoi U-Net ?**
- âœ… **Skip connections** : PrÃ©servent les dÃ©tails spatiaux fins (essentiel pour la localisation prÃ©cise)
- âœ… **Architecture encoder-decoder** : Capture le contexte global et les dÃ©tails locaux
- âœ… **Ã‰prouvÃ©** : Standard de facto pour la segmentation mÃ©dicale et biomÃ©dicale
- âœ… **Adaptable au 3D** : Extension naturelle pour donnÃ©es volumÃ©triques

### Structure gÃ©nÃ©rale

```
Input (1, 128, 128, 64)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENCODER PATH                          â”‚
â”‚  Conv3D â†’ ReLU â†’ Conv3D â†’ ReLU â†’ MaxPool3D             â”‚
â”‚  Channels: 1 â†’ 64 â†’ 128 â†’ 256 â†’ 512                    â”‚
â”‚  Spatial dims: 128Ã—128Ã—64 â†’ 64Ã—64Ã—32 â†’ 32Ã—32Ã—16 â†’ ...  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BOTTLENECK                            â”‚
â”‚  Conv3D â†’ ReLU â†’ Conv3D â†’ ReLU                         â”‚
â”‚  Channels: 512 â†’ 1024                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECODER PATH                          â”‚
â”‚  UpConv3D â†’ Concat(skip) â†’ Conv3D â†’ ReLU              â”‚
â”‚  Channels: 1024 â†’ 512 â†’ 256 â†’ 128 â†’ 64                â”‚
â”‚  Spatial dims: ... â†’ 32Ã—32Ã—16 â†’ 64Ã—64Ã—32 â†’ 128Ã—128Ã—64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output (1, 128, 128, 64) - Segmentation binaire
```

### DÃ©tails des couches

#### Encoder
- **Conv3D blocs** : 2 convolutions 3Ã—3Ã—3 par niveau
- **Activation** : ReLU (standard, non-linÃ©aritÃ©)
- **Pooling** : MaxPool3D 2Ã—2Ã—2 (rÃ©duction spatiale)
- **Dropout** : 0.3 (rÃ©gularisation contre overfitting)
- **Canaux** : 64 â†’ 128 â†’ 256 â†’ 512 (augmente avec la profondeur)

**Justification** :
- Convolutions 3Ã—3Ã—3 : Balance entre rÃ©ceptive field et nombre de paramÃ¨tres
- MaxPool : RÃ©duit la dimension spatiale, augmente le champ rÃ©cepteur
- Dropout 0.3 : Critique car peu de donnÃ©es d'entraÃ®nement

#### Bottleneck
- **Canaux** : 512 â†’ 1024
- **RÃ´le** : ReprÃ©sentation la plus abstraite/compacte du volume

#### Decoder
- **UpConv3D** : Upsampling + convolution transposÃ©e
- **Skip connections** : ConcatÃ©nation avec features de l'encoder
- **Conv3D blocs** : 2 convolutions aprÃ¨s chaque concat

**Justification skip connections** :
- RÃ©cupÃ¨re les dÃ©tails fins perdus lors du downsampling
- Essentiel pour localisation prÃ©cise des petites bactÃ©ries
- Aide le gradient Ã  se propager (Ã©vite vanishing gradient)

#### Output
- **Conv3D finale** : 1Ã—1Ã—1, 1 canal (segmentation binaire)
- **Pas d'activation** : Les logits sont passÃ©s directement Ã  la loss

---

## ğŸ“Š Fonction de Loss : SegmentationLoss

### Architecture de la loss

```python
SegmentationLoss = 0.3 Ã— BCE_weighted + 0.7 Ã— Dice_Loss
```

### Composant 1 : Binary Cross-Entropy (BCE) pondÃ©rÃ©e

```python
BCE_weighted = BCEWithLogitsLoss(pos_weight=10.0)
```

**RÃ´le** : Loss pixel-wise qui pÃ©nalise chaque erreur de classification

**PondÃ©ration (`pos_weight=10.0`)** :
- Multiplie la pÃ©nalitÃ© pour les faux nÃ©gatifs par 10
- Compense partiellement le dÃ©sÃ©quilibre (mais pas complÃ¨tement, car 10 << 130,000)
- Aide le modÃ¨le Ã  "dÃ©marrer" l'apprentissage des objets

**Justification** :
- âœ… Apprend Ã  rejeter le bruit voxel par voxel
- âœ… Force le modÃ¨le Ã  prÃªter attention aux rares voxels positifs
- âŒ Seule, elle ne suffit pas (le modÃ¨le peut prÃ©dire "fond" partout et avoir 99.999% de prÃ©cision)

### Composant 2 : Dice Loss

```python
Dice = (2 Ã— |Pred âˆ© Target| + Îµ) / (|Pred| + |Target| + Îµ)
Dice_Loss = 1 - Dice
```

**RÃ´le** : Mesure de similaritÃ© entre la prÃ©diction et la vÃ©ritÃ© terrain

**PropriÃ©tÃ©s** :
- Insensible au dÃ©sÃ©quilibre des classes (pas de biais vers la classe majoritaire)
- Ã‰value la segmentation globalement, pas pixel par pixel
- Score de 0 (aucun recouvrement) Ã  1 (recouvrement parfait)

**Justification** :
- âœ… Optimise directement la mÃ©trique de segmentation qui nous intÃ©resse
- âœ… Force le modÃ¨le Ã  produire des objets cohÃ©rents (pas juste quelques pixels)
- âœ… Crucial pour des donnÃ©es trÃ¨s dÃ©sÃ©quilibrÃ©es

### PondÃ©ration 30%/70%

```
Total_Loss = 0.3 Ã— BCE + 0.7 Ã— Dice
```

**Justification du ratio** :
- **70% Dice** : PrioritÃ© Ã  la segmentation globale des objets
- **30% BCE** : Affine la prÃ©cision voxel par voxel et aide Ã  rejeter le bruit

**Alternative testÃ©es** :
- 100% BCE â†’ PrÃ©dit "fond" partout (Dice = 0)
- 100% Dice â†’ Peut ignorer les dÃ©tails fins
- 50%/50% â†’ Moins bon que 30%/70% (empirique)

---

## ğŸ“ˆ MÃ©triques de suivi

### 1. Loss (principale)
- **UtilitÃ©** : Objectif d'optimisation
- **Ã‰volution attendue** : DÃ©croissance progressive de ~0.7 Ã  ~0.15-0.20

### 2. Dice Score
```
Dice = (2 Ã— TP) / (2Ã—TP + FP + FN)
```
- **UtilitÃ©** : MÃ©trique de segmentation standard
- **Objectif** : > 0.70 (bon), > 0.80 (excellent)
- **Ã‰volution attendue** :
  - Ã‰poques 1-20 : ~0.00 (apprend le fond)
  - Ã‰poques 20-50 : 0.10-0.30 (commence Ã  dÃ©tecter)
  - Ã‰poques 50-100 : 0.30-0.60 (apprentissage actif)
  - Ã‰poques 100+ : 0.60-0.80 (convergence)

### 3. Precision (PrÃ©cision)
```
Precision = TP / (TP + FP)
```
- **UtilitÃ©** : Mesure le taux de faux positifs
- **InterprÃ©tation** : Proportion de prÃ©dictions positives qui sont correctes
- **Objectif** : > 0.90 (rejette bien le bruit)
- **Critique pour notre cas** : Le modÃ¨le doit **rejeter massivement le bruit de diffraction**

### 4. Recall (SensibilitÃ©)
```
Recall = TP / (TP + FN)
```
- **UtilitÃ©** : Mesure le taux de dÃ©tection
- **InterprÃ©tation** : Proportion de vraies bactÃ©ries dÃ©tectÃ©es
- **Objectif** : > 0.60 (dÃ©tecte la majoritÃ©), > 0.80 (excellent)
- **Critique pour notre cas** : Le modÃ¨le doit **dÃ©tecter Ã  coup sÃ»r les bactÃ©ries**

### Trade-off Precision/Recall

```
Haute Precision (0.95) + Faible Recall (0.40)
â†’ DÃ©tecte peu, mais ce qu'il dÃ©tecte est correct
â†’ PrÃ©fÃ©rable en dÃ©but d'entraÃ®nement

Ã‰quilibre (0.85/0.70)
â†’ Objectif idÃ©al pour notre application
â†’ Rejette le bruit + dÃ©tecte la majoritÃ© des objets

Faible Precision (0.60) + Haute Recall (0.90)
â†’ DÃ©tecte tout mais beaucoup de faux positifs
â†’ Ã€ Ã©viter (trop de bruit acceptÃ©)
```

---

## âš™ï¸ HyperparamÃ¨tres et justifications

### EntraÃ®nement

| ParamÃ¨tre | Valeur | Justification |
|-----------|--------|---------------|
| `batch_size` | 2 | Limitation VRAM + reconstruction coÃ»teuse |
| `learning_rate` | 0.001 | 10Ã— supÃ©rieur au standard (0.0001) car loss custom |
| `num_epochs` | 200 | ProblÃ¨me difficile, convergence lente attendue |
| `optimizer` | Adam | Standard, adaptatif, fonctionne bien en 3D |
| `dropout` | 0.3 | RÃ©gularisation contre overfitting |

### Learning Rate Scheduler
- **Type** : ReduceLROnPlateau
- **Patience** : 20 Ã©poques
- **Factor** : 0.5 (LR Ã— 0.5)
- **Justification** : Affine progressivement l'apprentissage quand bloquÃ©

### Early Stopping
- **Patience** : 50 Ã©poques
- **MÃ©trique** : Validation Dice
- **Justification** : Large patience car convergence lente sur donnÃ©es dÃ©sÃ©quilibrÃ©es

### Patches 3D

| ParamÃ¨tre | Valeur | Justification |
|-----------|--------|---------------|
| `patch_size_xy` | 128Ã—128 | Balance contexte/mÃ©moire |
| `patch_size_z` | 64 | Suffisant pour capturer une bactÃ©rie |
| `stride_xy` | 96 | Overlap 25% pour cohÃ©rence spatiale |
| `stride_z` | 48 | Overlap 25% en profondeur |

**Justification overlap** :
- Ã‰vite les artefacts de bord entre patches
- Augmente le nombre d'exemples d'entraÃ®nement
- AmÃ©liore la robustesse de la prÃ©diction

---

## ğŸ”„ Pipeline d'entraÃ®nement

### 1. Chargement des donnÃ©es
```python
Hologramme 2D (512Ã—512)
    â†“
Reconstruction 3D (propagation angulaire)
    â†“
Volume intensitÃ© (512Ã—512Ã—200)
    â†“
Extraction patches (128Ã—128Ã—64)
```

### 2. Forward pass
```python
Input patch (1, 128, 128, 64)
    â†“
U-Net 3D
    â†“
Logits (1, 128, 128, 64)
    â†“
Loss (SegmentationLoss)
```

### 3. Backward pass
```python
Loss â†’ Gradients â†’ Optimizer.step()
```

### 4. MÃ©triques
```python
Sigmoid(Logits) â†’ PrÃ©dictions binaires
    â†“
Dice, Precision, Recall
```

---

## ğŸ¯ Performances attendues

### Phase 1 : Apprentissage du fond (Ã©poques 1-20)
- **Loss** : 0.70 â†’ 0.50
- **Dice** : 0.00 â†’ 0.10
- **Precision** : 0.00 â†’ 0.80
- **Recall** : 0.00 â†’ 0.05
- **InterprÃ©tation** : Le modÃ¨le apprend Ã  rejeter le bruit

### Phase 2 : DÃ©tection initiale (Ã©poques 20-50)
- **Loss** : 0.50 â†’ 0.30
- **Dice** : 0.10 â†’ 0.40
- **Precision** : 0.80 â†’ 0.85
- **Recall** : 0.05 â†’ 0.30
- **InterprÃ©tation** : Commence Ã  dÃ©tecter les bactÃ©ries

### Phase 3 : AmÃ©lioration (Ã©poques 50-100)
- **Loss** : 0.30 â†’ 0.20
- **Dice** : 0.40 â†’ 0.65
- **Precision** : 0.85 â†’ 0.88
- **Recall** : 0.30 â†’ 0.60
- **InterprÃ©tation** : Ã‰quilibre precision/recall s'amÃ©liore

### Phase 4 : Convergence (Ã©poques 100-200)
- **Loss** : 0.20 â†’ 0.15
- **Dice** : 0.65 â†’ 0.75
- **Precision** : 0.88 â†’ 0.90
- **Recall** : 0.60 â†’ 0.70
- **InterprÃ©tation** : Performance finale atteinte

---

## ğŸ” Cas d'usage spÃ©cifiques

### 1. BactÃ©ries isolÃ©es
- **DÃ©fi** : Signal faible noyÃ© dans le bruit
- **Solution** : Skip connections prÃ©servent les dÃ©tails fins
- **Attendu** : Haute prÃ©cision de dÃ©tection (Recall > 0.90)

### 2. BactÃ©ries proches (diffraction chevauchante)
- **DÃ©fi** : SÃ©paration de deux objets dont la diffraction se chevauche
- **Solution** : Contexte 3D capturÃ© par le rÃ©seau (pas juste 2D)
- **Attendu** : Performance rÃ©duite mais acceptable (Recall > 0.60)

### 3. RÃ©gions de bruit intense
- **DÃ©fi** : Faux positifs dans zones bruitÃ©es
- **Solution** : BCE + poids Ã©levÃ© sur precision
- **Attendu** : Faible taux de faux positifs (Precision > 0.85)

---

## ğŸ“ Notes d'implÃ©mentation

### Reconstruction Ã  la volÃ©e
- Les hologrammes sont reconstruits pendant l'entraÃ®nement
- Cache du dernier volume pour rÃ©utilisation des patches
- Temps : ~0.6s reconstruction + 0.5s par batch

### Ordre des axes
- **CuPy/Propagation** : (Z, Y, X)
- **PyTorch/U-Net** : (C, D, H, W) = (Channel, Depth, Height, Width)
- **Conversion** : Transpose automatique dans le dataset

### Gestion mÃ©moire GPU
- Batch size limitÃ© Ã  2 par la VRAM
- Volume complet ne tient pas en mÃ©moire â†’ approche par patches
- Trade-off : plus de patches = plus long mais meilleure couverture

---

## ğŸ”¬ AmÃ©liorations futures possibles

### 1. Attention mechanisms
- Ajouter des modules d'attention pour focaliser sur les rÃ©gions d'intÃ©rÃªt
- Peut amÃ©liorer la dÃ©tection dans les zones bruitÃ©es

### 2. Architecture plus profonde
- Tester ResNet blocks ou DenseNet blocks
- Peut amÃ©liorer l'apprentissage de features complexes

### 3. Multi-scale training
- EntraÃ®ner sur plusieurs rÃ©solutions simultanÃ©ment
- AmÃ©liore la robustesse aux Ã©chelles

### 4. Data augmentation 3D
- Rotations, flips, dÃ©formations Ã©lastiques
- Actuellement non implÃ©mentÃ© (Ã  tester)

### 5. Test-Time Augmentation (TTA)
- PrÃ©dire sur plusieurs versions augmentÃ©es et moyenner
- Peut amÃ©liorer les performances Ã  l'infÃ©rence

---

## ğŸ“š RÃ©fÃ©rences

1. **U-Net** : Ronneberger et al. (2015) - "U-Net: Convolutional Networks for Biomedical Image Segmentation"
2. **Dice Loss** : Milletari et al. (2016) - "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"
3. **3D U-Net** : Ã‡iÃ§ek et al. (2016) - "3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation"
4. **Class Imbalance** : Lin et al. (2017) - "Focal Loss for Dense Object Detection"

---

**Auteur** : Simon BECKER  
**Date** : FÃ©vrier 2026  
**Version** : 1.0
